{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "import analysis\n",
    "import db\n",
    "import fetcher\n",
    "from recordings import Recording\n",
    "from trim_recordings import detect_utterances\n",
    "\n",
    "import IPython.display\n",
    "from IPython.display import display\n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydub\n",
    "import scipy.ndimage\n",
    "from tqdm import tqdm\n",
    "\n",
    "import hashlib\n",
    "import io\n",
    "import multiprocessing\n",
    "\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = db.create_session('master.db')\n",
    "recordings_fetcher = fetcher.Fetcher('recordings', pool_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load recordings from the database and filter them according to some selection criteria:\n",
    "right species, contains the data we need, good quality, not too short and not too long.\n",
    "\n",
    "Then get them from the cache or download them if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5(string):\n",
    "    m = hashlib.md5()\n",
    "    m.update(string.encode('utf-8'))\n",
    "    return m.digest()\n",
    "\n",
    "recordings = [\n",
    "    r for r in session.query(Recording).filter(\n",
    "        #Recording.genus == 'Turdus', Recording.species == 'merula', # Merel\n",
    "        #Recording.genus == 'Passer', Recording.species == 'domesticus', # Huismus\n",
    "        Recording.genus == 'Parus', Recording.species == 'major', # Koolmees\n",
    "        #Recording.genus == 'Acrocephalus', Recording.species == 'palustris', # Bosrietzanger\n",
    "        #Recording.genus == 'Botaurus', Recording.species == 'stellaris', # Roerdomp\n",
    "    )\n",
    "    if r.url and r.audio_url and not r.background_species and r.quality == 'A' and 10 <= r.length_seconds <= 120\n",
    "]\n",
    "recordings.sort(key=lambda recording: md5(recording.recording_id))\n",
    "print(f'Found {len(recordings)} candidate recordings')\n",
    "\n",
    "recordings = recordings[:12]\n",
    "#recordings = recordings[12:24]\n",
    "recordings = {r.recording_id: r for r in recordings}\n",
    "\n",
    "def load_recording(recording):\n",
    "    data = recordings_fetcher.fetch_cached(recording.audio_url)\n",
    "    sound = analysis.load_sound(io.BytesIO(data))\n",
    "    return (recording.recording_id, sound)\n",
    "\n",
    "pool = multiprocessing.pool.Pool(8)\n",
    "sounds = dict(tqdm(pool.imap(load_recording, recordings.values(), 1), total=len(recordings)))\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze each recording and plot the intermediate and final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for recording_id, sound in sounds.items():\n",
    "    # Perform analysis.\n",
    "    mel_spectrogram = analysis.mel_spectrogram(sound)\n",
    "    noise_profile = analysis.noise_profile(mel_spectrogram)\n",
    "    noise_volume_db = analysis.noise_volume_db(noise_profile)\n",
    "    filtered_volume_db = analysis.filtered_volume_db(mel_spectrogram, noise_profile)\n",
    "    vocalizations = analysis.filter_vocalizations(\n",
    "        analysis.merge_vocalizations(\n",
    "            analysis.vocalizations(filtered_volume_db, noise_volume_db)))\n",
    "    \n",
    "    # Create figure.\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 3), gridspec_kw={'width_ratios': [8, 1]}, sharey='all')\n",
    "    \n",
    "    # Display spectrogram on the left.\n",
    "    img = librosa.display.specshow(librosa.power_to_db(mel_spectrogram),\n",
    "                                   x_axis='time', y_axis='mel',\n",
    "                                   cmap='magma', vmin=-80, vmax=0,\n",
    "                                   hop_length=hop_length, sr=analysis.SAMPLE_RATE, ax=ax[0])\n",
    "    ax[0].set_title(recording_id)\n",
    "    ax[0].title.set_url('https:' + recordings[recording_id].url)\n",
    "    \n",
    "    # Display vocalizations as transparent green rectangles on top of the spectrogram.\n",
    "    for (start, end) in vocalizations:\n",
    "        ax[0].add_patch(\n",
    "            Rectangle((start, 0), end - start, analysis.SAMPLE_RATE / 2,\n",
    "                      edgecolor='none', facecolor='#00ff0050'))\n",
    "    \n",
    "    # Plot volume of noise-filtered signal on top of spectrogram.\n",
    "    ax_right = ax[0].twinx()\n",
    "    xs = (np.arange(0, mel_spectrogram.shape[1]) + 0.5) * analysis.FFT_HOP_LENGTH / analysis.SAMPLE_RATE\n",
    "    ax_right.plot(xs, filtered_volume_db,\n",
    "                  linewidth=1.0)\n",
    "    ax_right.set_ylim(-80, 0)\n",
    "    \n",
    "    # Add lines at our vocalization thresholds.\n",
    "    ax_right.axhline(noise_volume_db, color='red')\n",
    "    ax_right.axhline(noise_volume_db + analysis.VOCALIZATION_TRIGGER_THRESHOLD_DB, color='yellow')\n",
    "    ax_right.axhline(noise_volume_db + analysis.VOCALIZATION_KEEP_THRESHOLD_DB, color='green')\n",
    "    \n",
    "    # Display noise profile on the right.\n",
    "    img = librosa.display.specshow(librosa.power_to_db(noise_profile),\n",
    "                                   y_axis='mel', ax=ax[1],\n",
    "                                   cmap='magma', vmin=-80, vmax=0)\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_ylabel(None)\n",
    "    ax[1].set_title(f'Noise: {noise_volume_db:.1f} dB')\n",
    "    fig.colorbar(img, ax=ax[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    display(IPython.display.Audio(sound, rate=analysis.SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a large empty cell to end with, to prevent scrolling when re-evaluating the output of the previous cell.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
