{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import analysis\n",
    "import recording_selection\n",
    "import db\n",
    "import fetcher\n",
    "from recordings import Recording, RecordingOverrides\n",
    "from species import CommonName\n",
    "from trim_recordings import detect_utterances\n",
    "\n",
    "import IPython\n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "import matplotlib\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydub\n",
    "import scipy.ndimage\n",
    "import scipy.signal\n",
    "from tqdm import tqdm\n",
    "\n",
    "import collections\n",
    "import hashlib\n",
    "import io\n",
    "import itertools\n",
    "import logging\n",
    "import multiprocessing\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=matplotlib.MatplotlibDeprecationWarning)\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "# logging.getLogger().setLevel(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = db.create_session('master.db')\n",
    "recordings_fetcher = fetcher.Fetcher('recordings', pool_size=8)\n",
    "recording_overrides = RecordingOverrides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load recordings from the database and filter them according to some selection criteria:\n",
    "right species, contains the data we need, good quality, not too short and not too long.\n",
    "\n",
    "Then get them from the cache or download them if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DUTCH_COMMON_NAME = 'Merel'\n",
    "COUNT = 12\n",
    "species = session.query(CommonName).filter(\n",
    "    CommonName.language_code == 'nl',\n",
    "    CommonName.common_name == DUTCH_COMMON_NAME,\n",
    ").one().species\n",
    "print(species.scientific_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selection = recording_selection.RecordingSelection(species, session, recordings_fetcher, recording_overrides)\n",
    "print(f'Found {len(selection.candidate_recordings)} candidate recordings; loading {COUNT} suitable ones...')\n",
    "\n",
    "analyses = list(itertools.islice(selection.suitable_recordings(), COUNT))\n",
    "\n",
    "for a in analyses:\n",
    "    fig, ax = plt.subplots(figsize=(9, 2))\n",
    "    librosa.display.specshow(librosa.power_to_db(a.mel_spectrogram),\n",
    "                             x_axis='time', y_axis='mel', fmin=0.0, fmax=analysis.SAMPLE_RATE / 2,\n",
    "                             cmap='magma', vmin=-80, vmax=0,\n",
    "                             hop_length=analysis.FFT_HOP_LENGTH, sr=analysis.SAMPLE_RATE, ax=ax)\n",
    "    ax.set_title(f'{a.recording.recording_id} - {a.recording.type}')\n",
    "    ax.title.set_url('https:' + a.recording.url)\n",
    "    for voc in a.vocalizations:\n",
    "        ax.add_patch(\n",
    "            Rectangle((voc.start, 0), voc.end - voc.start, analysis.SAMPLE_RATE / 2,\n",
    "                      edgecolor='none', facecolor='#00ff0050'))\n",
    "    plt.show()\n",
    "\n",
    "    IPython.display.display(IPython.display.Audio(a.sound, rate=analysis.SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocalizations = []\n",
    "for a in analyses:\n",
    "    vocalizations.extend(a.vocalizations)\n",
    "print(f'Found {len(vocalizations)} vocalizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_spectrograms(spectrograms, ax=None, **kwargs):\n",
    "    max_width = 3000\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for spectrogram in spectrograms:\n",
    "        h, w = spectrogram.shape\n",
    "        if x + w > max_width and x > 0:\n",
    "            x = 0\n",
    "            y -= h\n",
    "        ax.imshow(spectrogram, cmap='magma', origin='lower', aspect='auto', extent=(x, x + w, y - h, y), **kwargs)\n",
    "        ax.add_patch(Rectangle((x, y - h), w, h, fill=False, color='lime'))\n",
    "        x += w + 1\n",
    "        if x > max_width:\n",
    "            x = 0\n",
    "            y -= h\n",
    "    ax.axis('off')\n",
    "    ax.set_xlim(0, max_width)\n",
    "    ax.set_ylim(y - h, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vocalizations[11]\n",
    "fig, ax = plt.subplots(3, 1, figsize=(25, 6))\n",
    "img = librosa.display.specshow(librosa.power_to_db(voc.filtered_mel_spectrogram), x_axis='time', y_axis='mel', ax=ax[0])\n",
    "fig.colorbar(img, ax=ax[0])\n",
    "img = librosa.display.specshow(voc.mfccs, x_axis='time', cmap='magma', vmin=-100, vmax=100, ax=ax[1])\n",
    "fig.colorbar(img, ax=ax[1])\n",
    "img = librosa.display.specshow(np.array(voc.features).T, x_axis='time', cmap='magma', ax=ax[2])\n",
    "fig.colorbar(img, ax=ax[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "show_spectrograms((librosa.power_to_db(voc.filtered_mel_spectrogram) for voc in vocalizations), ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "show_spectrograms((voc.mfccs for voc in vocalizations), ax=ax, vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "show_spectrograms((np.array(voc.features).T for voc in vocalizations), ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for voc in vocalizations for f in voc.features]\n",
    "features.sort()\n",
    "print(f'Total features:  {len(features)}')\n",
    "print(f'Unique features: {len(set(features))}')\n",
    "fig, ax = plt.subplots(figsize=(25, 10))\n",
    "show_spectrograms(np.array_split(np.array(features).T, 12, axis=1), ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abandoned: attempt at similarity metric by sliding one spectrogram across the other.\n",
    "\n",
    "def similarity(self, other):\n",
    "    '''\n",
    "    Computes the similarity between this vocalization and another.\n",
    "    '''\n",
    "    threshold = 0.001\n",
    "    a = self.filtered_mel_spectrogram.copy()\n",
    "    b = other.filtered_mel_spectrogram.copy()\n",
    "    a[self.filtered_mel_spectrogram < threshold] = -1.0e-1\n",
    "    b[other.filtered_mel_spectrogram < threshold] = -1.0e-1\n",
    "    a[self.filtered_mel_spectrogram >= threshold] = 1.0\n",
    "    b[other.filtered_mel_spectrogram >= threshold] = 1.0\n",
    "    # Convolution flips the second array, so we need to pre-flip it here to come out the right way.\n",
    "    # `np.correlate` does not flip, but only works on 1D arrays.\n",
    "    max_correlation = np.amax(scipy.signal.convolve(a, np.flip(b), mode='valid'))\n",
    "    return max_correlation / min(np.sum(a**2), np.sum(b**2))\n",
    "\n",
    "n = 12 # len(vocalizations)\n",
    "vocalization_indices = np.arange(0, n)\n",
    "similarity_matrix = np.zeros((n, n))\n",
    "for (i, j) in tqdm([(i, j) for i in range(0, n) for j in range(i, n)]):\n",
    "    s = similarity(vocalizations[i], vocalizations[j])\n",
    "    similarity_matrix[i, j] = s\n",
    "    similarity_matrix[j, i] = s\n",
    "print(similarity_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
