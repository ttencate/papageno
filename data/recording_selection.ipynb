{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import analysis\n",
    "import db\n",
    "import fetcher\n",
    "from recording_selection import RecordingSelection, load_recording\n",
    "from recordings import Recording, RecordingOverrides\n",
    "from species import CommonName\n",
    "from trim_recordings import detect_utterances\n",
    "\n",
    "import IPython\n",
    "import librosa\n",
    "import librosa.display\n",
    "import librosa.feature\n",
    "import matplotlib\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydub\n",
    "import scipy.ndimage\n",
    "from tqdm import tqdm\n",
    "\n",
    "import collections\n",
    "import hashlib\n",
    "import io\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=matplotlib.MatplotlibDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = db.create_session('master.db')\n",
    "recordings_fetcher = fetcher.Fetcher('recordings', pool_size=8)\n",
    "recording_overrides = RecordingOverrides()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load recordings from the database and filter them according to some selection criteria:\n",
    "right species, contains the data we need, good quality, not too short and not too long.\n",
    "\n",
    "Then get them from the cache or download them if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUTCH_COMMON_NAME = 'Merel'\n",
    "COUNT = 12\n",
    "\n",
    "species = session.query(CommonName).filter(\n",
    "    CommonName.language_code == 'nl',\n",
    "    CommonName.common_name == DUTCH_COMMON_NAME,\n",
    ").one().species\n",
    "\n",
    "selection = RecordingSelection(species, session, recordings_fetcher, recording_overrides)\n",
    "print(f'Found {len(selection.candidate_recordings)} candidate recordings')\n",
    "recordings = {\n",
    "    recording.recording_id: recording\n",
    "    for recording in selection.candidate_recordings[:COUNT]\n",
    "}\n",
    "sounds = {\n",
    "    recording.recording_id: load_recording(recording, recordings_fetcher)\n",
    "    for (recording_id, recording) in tqdm(recordings.items())\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by descending perceptual noise volume so we can see if the ordering makes sense, and where to put the threshold for deciding whether to keep a recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyses = {}\n",
    "for recording_id, sound in sounds.items():\n",
    "    analyses[recording_id] = analysis.Analysis(recordings[recording_id], sound)\n",
    "    \n",
    "specshow_args = dict(\n",
    "    x_axis='time',\n",
    "    y_axis='log', fmin=0, fmax=analysis.SAMPLE_RATE / 2,\n",
    "    cmap='magma', vmin=-80, vmax=0,\n",
    "    hop_length=analysis.FFT_HOP_LENGTH, sr=analysis.SAMPLE_RATE,\n",
    ")\n",
    "\n",
    "for (recording_id, a) in sorted(analyses.items(), key=lambda ia: ia[1].perceptual_noise_volume_db):\n",
    "    # Make sure to use the same reference amplitude for the dB conversion on both sides of the plot.\n",
    "    ref = np.amax(a.spectrogram)\n",
    "\n",
    "    # Create figure.\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(9, 3), gridspec_kw={'width_ratios': [8, 1]}, sharey='all')\n",
    "    \n",
    "    # Display spectrogram on the left.\n",
    "    img = librosa.display.specshow(librosa.amplitude_to_db(a.spectrogram, ref=ref), **specshow_args, ax=ax[0])\n",
    "    ax[0].set_title(f'{recording_id} - {recordings[recording_id].type}')\n",
    "    ax[0].title.set_url('https:' + recordings[recording_id].url)\n",
    "    \n",
    "    # Display noise profile on the right.\n",
    "    img = librosa.display.specshow(librosa.amplitude_to_db(a.noise_profile, ref=ref), **specshow_args, ax=ax[1])\n",
    "    ax[1].set_xticks([])\n",
    "    ax[1].set_xlabel(None)\n",
    "    ax[1].set_ylabel(None)\n",
    "    ax[1].set_title(f'{a.perceptual_noise_volume_db:.1f} dB')\n",
    "    fig.colorbar(img, ax=ax[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    IPython.display.display(IPython.display.Audio(sounds[recording_id], rate=analysis.SAMPLE_RATE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
